{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a389be47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy_transformers\n",
      "  Downloading spacy_transformers-1.1.8-py2.py3-none-any.whl (53 kB)\n",
      "     ---------------------------------------- 53.4/53.4 kB 2.7 MB/s eta 0:00:00\n",
      "Collecting torch>=1.6.0\n",
      "  Downloading torch-1.12.1-cp39-cp39-win_amd64.whl (161.8 MB)\n",
      "     ------------------------------------- 161.8/161.8 MB 13.9 MB/s eta 0:00:00\n",
      "Collecting spacy-alignments<1.0.0,>=0.7.2\n",
      "  Downloading spacy_alignments-0.8.5-cp39-cp39-win_amd64.whl (187 kB)\n",
      "     ------------------------------------- 187.2/187.2 kB 11.8 MB/s eta 0:00:00\n",
      "Collecting srsly<3.0.0,>=2.4.0\n",
      "  Using cached srsly-2.4.4-cp39-cp39-win_amd64.whl (450 kB)\n",
      "Collecting spacy<4.0.0,>=3.4.0\n",
      "  Using cached spacy-3.4.1-cp39-cp39-win_amd64.whl (11.8 MB)\n",
      "Collecting transformers<4.22.0,>=3.4.0\n",
      "  Downloading transformers-4.21.1-py3-none-any.whl (4.7 MB)\n",
      "     ---------------------------------------- 4.7/4.7 MB 37.2 MB/s eta 0:00:00\n",
      "Collecting thinc<8.2.0,>=8.1.0\n",
      "  Using cached thinc-8.1.0-cp39-cp39-win_amd64.whl (1.3 MB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy<4.0.0,>=3.4.0->spacy_transformers) (2.28.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy<4.0.0,>=3.4.0->spacy_transformers) (1.0.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy<4.0.0,>=3.4.0->spacy_transformers) (1.23.2)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy<4.0.0,>=3.4.0->spacy_transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy<4.0.0,>=3.4.0->spacy_transformers) (4.64.0)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Using cached catalogue-2.0.8-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy<4.0.0,>=3.4.0->spacy_transformers) (61.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy<4.0.0,>=3.4.0->spacy_transformers) (21.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy<4.0.0,>=3.4.0->spacy_transformers) (2.0.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy<4.0.0,>=3.4.0->spacy_transformers) (3.0.10)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy<4.0.0,>=3.4.0->spacy_transformers) (1.9.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy<4.0.0,>=3.4.0->spacy_transformers) (0.6.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy<4.0.0,>=3.4.0->spacy_transformers) (0.10.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy<4.0.0,>=3.4.0->spacy_transformers) (3.0.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy<4.0.0,>=3.4.0->spacy_transformers) (1.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy<4.0.0,>=3.4.0->spacy_transformers) (3.0.7)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy<4.0.0,>=3.4.0->spacy_transformers) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from torch>=1.6.0->spacy_transformers) (4.3.0)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp39-cp39-win_amd64.whl (151 kB)\n",
      "     ---------------------------------------- 151.6/151.6 kB ? eta 0:00:00\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
      "     ---------------------------------------- 101.5/101.5 kB ? eta 0:00:00\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.8.0-py3-none-any.whl (10 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp39-cp39-win_amd64.whl (3.3 MB)\n",
      "     ---------------------------------------- 3.3/3.3 MB 42.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from transformers<4.22.0,>=3.4.0->spacy_transformers) (2022.8.17)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from packaging>=20.0->spacy<4.0.0,>=3.4.0->spacy_transformers) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from pathy>=0.3.5->spacy<4.0.0,>=3.4.0->spacy_transformers) (5.2.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.0->spacy_transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.0->spacy_transformers) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.0->spacy_transformers) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.0->spacy_transformers) (2.1.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy<4.0.0,>=3.4.0->spacy_transformers) (0.7.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<4.0.0,>=3.4.0->spacy_transformers) (0.4.5)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<4.0.0,>=3.4.0->spacy_transformers) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from jinja2->spacy<4.0.0,>=3.4.0->spacy_transformers) (2.1.1)\n",
      "Installing collected packages: tokenizers, torch, spacy-alignments, pyyaml, filelock, catalogue, srsly, huggingface-hub, transformers, thinc, spacy, spacy_transformers\n",
      "  Attempting uninstall: catalogue\n",
      "    Found existing installation: catalogue 1.0.0\n",
      "    Uninstalling catalogue-1.0.0:\n",
      "      Successfully uninstalled catalogue-1.0.0\n",
      "  Attempting uninstall: srsly\n",
      "    Found existing installation: srsly 1.0.5\n",
      "    Uninstalling srsly-1.0.5:\n",
      "      Successfully uninstalled srsly-1.0.5\n",
      "  Attempting uninstall: thinc\n",
      "    Found existing installation: thinc 7.4.5\n",
      "    Uninstalling thinc-7.4.5:\n",
      "      Successfully uninstalled thinc-7.4.5\n",
      "  Attempting uninstall: spacy\n",
      "    Found existing installation: spacy 2.3.7\n",
      "    Uninstalling spacy-2.3.7:\n",
      "      Successfully uninstalled spacy-2.3.7\n",
      "Successfully installed catalogue-2.0.8 filelock-3.8.0 huggingface-hub-0.8.1 pyyaml-6.0 spacy-3.4.1 spacy-alignments-0.8.5 spacy_transformers-1.1.8 srsly-2.4.4 thinc-8.1.0 tokenizers-0.12.1 torch-1.12.1 transformers-4.21.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "en-core-web-sm 2.3.1 requires spacy<2.4.0,>=2.3.0, but you have spacy 3.4.1 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (3.4.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy) (61.2.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy) (1.23.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy) (8.1.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy) (1.0.8)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy) (0.6.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy) (3.0.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy) (1.0.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy) (4.64.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy) (3.0.7)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy) (0.4.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy) (1.9.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy) (2.4.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4->spacy) (4.3.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.1.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.5)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy_transformers\n",
    "!pip install -U spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f51f1f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DeepLearning\\envs\\official_Tasks\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\DeepLearning\\envs\\official_Tasks\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99f1ebaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import DocBin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0995ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b44ae60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.4.1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c77991bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Aug 20 08:55:43 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 516.94       Driver Version: 516.94       CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   43C    P8    11W /  N/A |    122MiB /  8192MiB |      5%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      4316    C+G   ...ightStudio-background.exe    N/A      |\n",
      "|    0   N/A  N/A      7436    C+G   ...mmandCenterBackground.exe    N/A      |\n",
      "|    0   N/A  N/A     11584    C+G   ...ystemEventUtilityHost.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94517cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de2683b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_data = json.load(open('C:\\\\Users\\\\DAVID CHRISTOPHER\\\\NewResumeParser\\\\CV-Parsing-using-Spacy-3-master\\\\CV-Parsing-using-Spacy-3-master\\\\data\\\\training\\\\train_data1.json','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a78f335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5fa0a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Usage: python -m spacy init fill-config [OPTIONS] BASE_PATH [OUTPUT_FILE]\n",
      "Try 'python -m spacy init fill-config --help' for help.\n",
      "\n",
      "Error: Got unexpected extra arguments (C:\\Users\\DAVID CHRISTOPHER\\NewResumeParser\\CV-Parsing-using-Spacy-3-master\\CV-Parsing-using-Spacy-3-master\\data\\training\\config.cfg)\n"
     ]
    }
   ],
   "source": [
    "##!python -m spacy init fill-config C:\\Users\\DAVID CHRISTOPHER\\NewResumeParser\\CV-Parsing-using-Spacy-3-master\\CV-Parsing-using-Spacy-3-master\\data\\training\\base_config.cfg C:\\Users\\DAVID CHRISTOPHER\\NewResumeParser\\CV-Parsing-using-Spacy-3-master\\CV-Parsing-using-Spacy-3-master\\data\\training\\config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5465c696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: python -m spacy init fill-config [OPTIONS] BASE_PATH [OUTPUT_FILE]\n",
      "\n",
      "  Fill partial config file with default values. Will add all missing settings\n",
      "  from the default config and will create all objects, check the registered\n",
      "  functions for their default values and update the base config. This command\n",
      "  can be used with a config generated via the training quickstart widget:\n",
      "  https://spacy.io/usage/training#quickstart\n",
      "\n",
      "  DOCS: https://spacy.io/api/cli#init-fill-config\n",
      "\n",
      "Arguments:\n",
      "  BASE_PATH      Path to base config to fill  [required]\n",
      "  [OUTPUT_FILE]  Path to output .cfg file (or - for stdout)  [default: -]\n",
      "\n",
      "Options:\n",
      "  -pt, --pretraining            Include config for pretraining (with 'spacy\n",
      "                                pretrain')\n",
      "  -D, --diff                    Print a visual diff highlighting the changes\n",
      "  -c, --code-path, --code PATH  Path to Python file with additional code\n",
      "                                (registered functions) to be imported\n",
      "  --help                        Show this message and exit.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9e004b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (22.1.2)\n",
      "Collecting pip\n",
      "  Downloading pip-22.2.2-py3-none-any.whl (2.0 MB)\n",
      "     ---------------------------------------- 2.0/2.0 MB 21.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (61.2.0)\n",
      "Collecting setuptools\n",
      "  Using cached setuptools-65.1.0-py3-none-any.whl (1.2 MB)\n",
      "Requirement already satisfied: wheel in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (0.37.1)\n",
      "Installing collected packages: setuptools, pip\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 61.2.0\n",
      "    Uninstalling setuptools-61.2.0:\n",
      "      Successfully uninstalled setuptools-61.2.0\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 22.1.2\n",
      "    Uninstalling pip-22.1.2:\n",
      "      Successfully uninstalled pip-22.1.2\n",
      "Successfully installed pip-22.2.2 setuptools-65.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "en-core-web-sm 2.3.1 requires spacy<2.4.0,>=2.3.0, but you have spacy 3.4.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install -U pip setuptools wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7768535c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (3.4.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy) (3.0.7)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy) (1.0.8)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy) (0.4.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy) (1.0.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy) (1.9.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy) (65.1.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy) (0.6.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy) (1.23.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy) (3.0.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy) (4.64.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy) (2.4.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy) (8.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4->spacy) (4.3.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.6.15)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.5)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec0b3bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.4.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.0/en_core_web_sm-3.4.0-py3-none-any.whl (12.8 MB)\n",
      "     --------------------------------------- 12.8/12.8 MB 21.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.5.0,>=3.4.0 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from en-core-web-sm==3.4.0) (3.4.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.6.2)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.4.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.8)\n",
      "Requirement already satisfied: setuptools in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (65.1.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.10.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.3.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.9.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.64.0)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (8.1.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.23.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.4.4)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.28.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (21.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.10)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.3.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.7.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.4.5)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\deeplearning\\envs\\official_tasks\\lib\\site-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.1.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "  Attempting uninstall: en-core-web-sm\n",
      "    Found existing installation: en-core-web-sm 2.3.1\n",
      "    Uninstalling en-core-web-sm-2.3.1:\n",
      "      Successfully uninstalled en-core-web-sm-2.3.1\n",
      "Successfully installed en-core-web-sm-3.4.0\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04433bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Auto-filled config with all values\n",
      "\u001b[1m\n",
      "============================= START CONFIG DIFF =============================\u001b[0m\n",
      "\n",
      "[paths]\n",
      "train = null\n",
      "dev = null\n",
      "vectors = \"en_core_web_lg\"\n",
      "\u001b[38;5;16;48;5;2minit_tok2vec = null\u001b[0m\n",
      "\n",
      "[system]\n",
      "gpu_allocator = null\n",
      "\u001b[38;5;16;48;5;2mseed = 0\u001b[0m\n",
      "\n",
      "[nlp]\n",
      "lang = \"en\"\n",
      "pipeline = [\"tok2vec\",\"ner\"]\n",
      "batch_size = 1000\n",
      "\u001b[38;5;16;48;5;2mdisabled = []\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mbefore_creation = null\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mafter_creation = null\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mafter_pipeline_creation = null\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mtokenizer = {\"@tokenizers\":\"spacy.Tokenizer.v1\"}\u001b[0m\n",
      "\n",
      "[components]\n",
      "\n",
      "[components.ner]\n",
      "factory = \"ner\"\n",
      "\u001b[38;5;16;48;5;2mincorrect_spans_key = null\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mmoves = null\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mscorer = {\"@scorers\":\"spacy.ner_scorer.v1\"}\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mupdate_with_oracle_cut_size = 100\u001b[0m\n",
      "\n",
      "[components.ner.model]\n",
      "@architectures = \"spacy.TransitionBasedParser.v2\"\n",
      "state_type = \"ner\"\n",
      "extra_state_tokens = false\n",
      "hidden_width = 64\n",
      "maxout_pieces = 2\n",
      "use_upper = true\n",
      "nO = null\n",
      "\n",
      "[components.ner.model.tok2vec]\n",
      "@architectures = \"spacy.Tok2VecListener.v1\"\n",
      "width = ${components.tok2vec.model.encode.width}\n",
      "\u001b[38;5;16;48;5;2mupstream = \"*\"\u001b[0m\n",
      "\n",
      "[components.tok2vec]\n",
      "factory = \"tok2vec\"\n",
      "\n",
      "[components.tok2vec.model]\n",
      "@architectures = \"spacy.Tok2Vec.v2\"\n",
      "\n",
      "[components.tok2vec.model.embed]\n",
      "@architectures = \"spacy.MultiHashEmbed.v2\"\n",
      "width = ${components.tok2vec.model.encode.width}\n",
      "attrs = [\"ORTH\",\"SHAPE\"]\n",
      "rows = [5000,2500]\n",
      "include_static_vectors = true\n",
      "\n",
      "[components.tok2vec.model.encode]\n",
      "@architectures = \"spacy.MaxoutWindowEncoder.v2\"\n",
      "width = 256\n",
      "depth = 8\n",
      "window_size = 1\n",
      "maxout_pieces = 3\n",
      "\n",
      "[corpora]\n",
      "\n",
      "[corpora.dev]\n",
      "@readers = \"spacy.Corpus.v1\"\n",
      "path = ${paths.dev}\n",
      "max_length = 0\n",
      "\u001b[38;5;16;48;5;2mgold_preproc = false\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mlimit = 0\u001b[0m\n",
      "\u001b[38;5;16;48;5;2maugmenter = null\u001b[0m\n",
      "\n",
      "[corpora.train]\n",
      "@readers = \"spacy.Corpus.v1\"\n",
      "path = ${paths.train}\n",
      "max_length = 0\n",
      "\u001b[38;5;16;48;5;2mgold_preproc = false\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mlimit = 0\u001b[0m\n",
      "\u001b[38;5;16;48;5;2maugmenter = null\u001b[0m\n",
      "\n",
      "[training]\n",
      "dev_corpus = \"corpora.dev\"\n",
      "train_corpus = \"corpora.train\"\n",
      "\u001b[38;5;16;48;5;2mseed = ${system.seed}\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mgpu_allocator = ${system.gpu_allocator}\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mdropout = 0.1\u001b[0m\n",
      "\u001b[38;5;16;48;5;2maccumulate_gradient = 1\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mpatience = 1600\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mmax_epochs = 0\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mmax_steps = 20000\u001b[0m\n",
      "\u001b[38;5;16;48;5;2meval_frequency = 200\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mfrozen_components = []\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mannotating_components = []\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mbefore_to_disk = null\u001b[0m\n",
      "\u001b[38;5;16;48;5;1moptimizer = {\"@optimizers\":\"Adam.v1\"}\u001b[0m\n",
      "\n",
      "[training.batcher]\n",
      "@batchers = \"spacy.batch_by_words.v1\"\n",
      "discard_oversize = false\n",
      "tolerance = 0.2\n",
      "\u001b[38;5;16;48;5;2mget_length = null\u001b[0m\n",
      "\n",
      "[training.batcher.size]\n",
      "@schedules = \"compounding.v1\"\n",
      "start = 100\n",
      "stop = 1000\n",
      "compound = 1.001\n",
      "\u001b[38;5;16;48;5;2mt = 0.0\u001b[0m\n",
      "\u001b[38;5;16;48;5;2m\u001b[0m\n",
      "\u001b[38;5;16;48;5;2m[training.logger]\u001b[0m\n",
      "\u001b[38;5;16;48;5;2m@loggers = \"spacy.ConsoleLogger.v1\"\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mprogress_bar = false\u001b[0m\n",
      "\u001b[38;5;16;48;5;2m\u001b[0m\n",
      "\u001b[38;5;16;48;5;2m[training.optimizer]\u001b[0m\n",
      "\u001b[38;5;16;48;5;2m@optimizers = \"Adam.v1\"\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mbeta1 = 0.9\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mbeta2 = 0.999\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mL2_is_weight_decay = true\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mL2 = 0.01\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mgrad_clip = 1.0\u001b[0m\n",
      "\u001b[38;5;16;48;5;2muse_averages = false\u001b[0m\n",
      "\u001b[38;5;16;48;5;2meps = 0.00000001\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mlearn_rate = 0.001\u001b[0m\n",
      "\u001b[38;5;16;48;5;2m\u001b[0m\n",
      "\u001b[38;5;16;48;5;2m[training.score_weights]\u001b[0m\n",
      "\u001b[38;5;16;48;5;2ments_f = 1.0\u001b[0m\n",
      "\u001b[38;5;16;48;5;2ments_p = 0.0\u001b[0m\n",
      "\u001b[38;5;16;48;5;2ments_r = 0.0\u001b[0m\n",
      "\u001b[38;5;16;48;5;2ments_per_type = null\u001b[0m\n",
      "\u001b[38;5;16;48;5;2m\u001b[0m\n",
      "\u001b[38;5;16;48;5;2m[pretraining]\u001b[0m\n",
      "\n",
      "[initialize]\n",
      "vectors = ${paths.vectors}\n",
      "\u001b[38;5;16;48;5;2minit_tok2vec = ${paths.init_tok2vec}\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mvocab_data = null\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mlookups = null\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mbefore_init = null\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mafter_init = null\u001b[0m\n",
      "\u001b[38;5;16;48;5;2m\u001b[0m\n",
      "\u001b[38;5;16;48;5;2m[initialize.components]\u001b[0m\n",
      "\u001b[38;5;16;48;5;2m\u001b[0m\n",
      "\u001b[38;5;16;48;5;2m[initialize.tokenizer]\u001b[0m\n",
      "\u001b[1m\n",
      "============================== END CONFIG DIFF ==============================\u001b[0m\n",
      "\n",
      "[+] Saved config\n",
      "output.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train output.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config base_config.cfg output.cfg --diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9737bfb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Auto-filled config with all values\n",
      "\u001b[1m\n",
      "============================= START CONFIG DIFF =============================\u001b[0m\n",
      "\n",
      "[paths]\n",
      "train = null\n",
      "dev = null\n",
      "vectors = null\n",
      "\u001b[38;5;16;48;5;2minit_tok2vec = null\u001b[0m\n",
      "\n",
      "[system]\n",
      "gpu_allocator = \"pytorch\"\n",
      "\u001b[38;5;16;48;5;2mseed = 0\u001b[0m\n",
      "\n",
      "[nlp]\n",
      "lang = \"en\"\n",
      "pipeline = [\"transformer\",\"ner\"]\n",
      "batch_size = 128\n",
      "\u001b[38;5;16;48;5;2mdisabled = []\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mbefore_creation = null\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mafter_creation = null\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mafter_pipeline_creation = null\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mtokenizer = {\"@tokenizers\":\"spacy.Tokenizer.v1\"}\u001b[0m\n",
      "\n",
      "[components]\n",
      "\n",
      "[components.ner]\n",
      "factory = \"ner\"\n",
      "\u001b[38;5;16;48;5;2mincorrect_spans_key = null\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mmoves = null\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mscorer = {\"@scorers\":\"spacy.ner_scorer.v1\"}\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mupdate_with_oracle_cut_size = 100\u001b[0m\n",
      "\n",
      "[components.ner.model]\n",
      "@architectures = \"spacy.TransitionBasedParser.v2\"\n",
      "state_type = \"ner\"\n",
      "extra_state_tokens = false\n",
      "hidden_width = 64\n",
      "maxout_pieces = 2\n",
      "use_upper = false\n",
      "nO = null\n",
      "\n",
      "[components.ner.model.tok2vec]\n",
      "@architectures = \"spacy-transformers.TransformerListener.v1\"\n",
      "grad_factor = 1.0\n",
      "pooling = {\"@layers\":\"reduce_mean.v1\"}\n",
      "\u001b[38;5;16;48;5;2mupstream = \"*\"\u001b[0m\n",
      "\n",
      "[components.transformer]\n",
      "factory = \"transformer\"\n",
      "\u001b[38;5;16;48;5;2mmax_batch_items = 4096\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mset_extra_annotations = {\"@annotation_setters\":\"spacy-transformers.null_annotation_setter.v1\"}\u001b[0m\n",
      "\n",
      "[components.transformer.model]\n",
      "@architectures = \"spacy-transformers.TransformerModel.v3\"\n",
      "name = \"roberta-base\"\n",
      "\u001b[38;5;16;48;5;2mmixed_precision = false\u001b[0m\n",
      "\n",
      "[components.transformer.model.get_spans]\n",
      "@span_getters = \"spacy-transformers.strided_spans.v1\"\n",
      "window = 128\n",
      "stride = 96\n",
      "\n",
      "\u001b[38;5;16;48;5;2m[components.transformer.model.grad_scaler_config]\u001b[0m\n",
      "\u001b[38;5;16;48;5;2m\u001b[0m\n",
      "[components.transformer.model.tokenizer_config]\n",
      "use_fast = true\n",
      "\u001b[38;5;16;48;5;2m\u001b[0m\n",
      "\u001b[38;5;16;48;5;2m[components.transformer.model.transformer_config]\u001b[0m\n",
      "\n",
      "[corpora]\n",
      "\n",
      "[corpora.dev]\n",
      "@readers = \"spacy.Corpus.v1\"\n",
      "path = ${paths.dev}\n",
      "max_length = 0\n",
      "\u001b[38;5;16;48;5;2mgold_preproc = false\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mlimit = 0\u001b[0m\n",
      "\u001b[38;5;16;48;5;2maugmenter = null\u001b[0m\n",
      "\n",
      "[corpora.train]\n",
      "@readers = \"spacy.Corpus.v1\"\n",
      "path = ${paths.train}\n",
      "max_length = 0\n",
      "\u001b[38;5;16;48;5;2mgold_preproc = false\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mlimit = 0\u001b[0m\n",
      "\u001b[38;5;16;48;5;2maugmenter = null\u001b[0m\n",
      "\n",
      "[training]\n",
      "accumulate_gradient = 3\n",
      "dev_corpus = \"corpora.dev\"\n",
      "train_corpus = \"corpora.train\"\n",
      "\u001b[38;5;16;48;5;2mseed = ${system.seed}\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mgpu_allocator = ${system.gpu_allocator}\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mdropout = 0.1\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mpatience = 1600\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mmax_epochs = 0\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mmax_steps = 20000\u001b[0m\n",
      "\u001b[38;5;16;48;5;2meval_frequency = 200\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mfrozen_components = []\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mannotating_components = []\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mbefore_to_disk = null\u001b[0m\n",
      "\n",
      "[training.batcher]\n",
      "@batchers = \"spacy.batch_by_padded.v1\"\n",
      "discard_oversize = true\n",
      "size = 2000\n",
      "buffer = 256\n",
      "\u001b[38;5;16;48;5;2mget_length = null\u001b[0m\n",
      "\u001b[38;5;16;48;5;2m\u001b[0m\n",
      "\u001b[38;5;16;48;5;2m[training.logger]\u001b[0m\n",
      "\u001b[38;5;16;48;5;2m@loggers = \"spacy.ConsoleLogger.v1\"\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mprogress_bar = false\u001b[0m\n",
      "\n",
      "[training.optimizer]\n",
      "@optimizers = \"Adam.v1\"\n",
      "\u001b[38;5;16;48;5;2mbeta1 = 0.9\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mbeta2 = 0.999\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mL2_is_weight_decay = true\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mL2 = 0.01\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mgrad_clip = 1.0\u001b[0m\n",
      "\u001b[38;5;16;48;5;2muse_averages = false\u001b[0m\n",
      "\u001b[38;5;16;48;5;2meps = 0.00000001\u001b[0m\n",
      "\n",
      "[training.optimizer.learn_rate]\n",
      "@schedules = \"warmup_linear.v1\"\n",
      "warmup_steps = 250\n",
      "total_steps = 20000\n",
      "initial_rate = 0.00005\n",
      "\n",
      "\u001b[38;5;16;48;5;2m[training.score_weights]\u001b[0m\n",
      "\u001b[38;5;16;48;5;2ments_f = 1.0\u001b[0m\n",
      "\u001b[38;5;16;48;5;2ments_p = 0.0\u001b[0m\n",
      "\u001b[38;5;16;48;5;2ments_r = 0.0\u001b[0m\n",
      "\u001b[38;5;16;48;5;2ments_per_type = null\u001b[0m\n",
      "\u001b[38;5;16;48;5;2m\u001b[0m\n",
      "\u001b[38;5;16;48;5;2m[pretraining]\u001b[0m\n",
      "\u001b[38;5;16;48;5;2m\u001b[0m\n",
      "[initialize]\n",
      "vectors = ${paths.vectors}\n",
      "\u001b[38;5;16;48;5;2minit_tok2vec = ${paths.init_tok2vec}\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mvocab_data = null\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mlookups = null\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mbefore_init = null\u001b[0m\n",
      "\u001b[38;5;16;48;5;2mafter_init = null\u001b[0m\n",
      "\u001b[38;5;16;48;5;2m\u001b[0m\n",
      "\u001b[38;5;16;48;5;2m[initialize.components]\u001b[0m\n",
      "\u001b[38;5;16;48;5;2m\u001b[0m\n",
      "\u001b[38;5;16;48;5;2m[initialize.tokenizer]\u001b[0m\n",
      "\u001b[1m\n",
      "============================== END CONFIG DIFF ==============================\u001b[0m\n",
      "\n",
      "[+] Saved config\n",
      "output1.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train output1.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config base1_config.cfg output1.cfg --diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1f32cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spacy_doc(file, data):\n",
    "    nlp = spacy.blank('en')\n",
    "    db = DocBin()\n",
    "    \n",
    "    for text, annot in tqdm(data):\n",
    "        doc = nlp.make_doc(text)\n",
    "        annot = annot['entities']\n",
    "        \n",
    "        ents = []\n",
    "        entity_indices = []\n",
    "        \n",
    "        for start, end, label  in annot:\n",
    "            skip_entity = False\n",
    "            for idx in range(start, end):\n",
    "                if idx in entity_indices:\n",
    "                    skip_entity = True\n",
    "                    break\n",
    "            if skip_entity == True:\n",
    "                continue\n",
    "                    \n",
    "            entity_indices = entity_indices + list(range(start, end))\n",
    "                \n",
    "            try:\n",
    "                span = doc.char_span(start, end, label=label, alignment_mode='strict')\n",
    "            except:\n",
    "                continue\n",
    "                    \n",
    "            if span is None:\n",
    "                err_data = str([start, end]) +\"   \"+ str(text) + \"\\n\"\n",
    "                file.write(err_data)\n",
    "                    \n",
    "            else:\n",
    "                ents.append(span)\n",
    "                    \n",
    "        try:\n",
    "            doc.ents = ents\n",
    "            db.add(doc)            \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    return db  \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be8b7fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "286ba1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f4fa659",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(cv_data, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "384a2f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 60)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a742a5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 140/140 [00:01<00:00, 116.48it/s]\n",
      "100%|██████████| 60/60 [00:00<00:00, 84.31it/s]\n"
     ]
    }
   ],
   "source": [
    "file  = open('error.txt', 'w')\n",
    "db=get_spacy_doc(file, train)\n",
    "db.to_disk('train_data.spacy')\n",
    "\n",
    "db=get_spacy_doc(file, test)\n",
    "db.to_disk('test_data.spacy')\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54dd3903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(db.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cec589",
   "metadata": {},
   "outputs": [],
   "source": [
    "##!python -m spacy train output1.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87e6d241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Created output directory: output\n",
      "[i] Saving to output directory: output\n",
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['transformer', 'ner']\n",
      "[i] Initial learn rate: 0.0\n",
      "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  -------------  --------  ------  ------  ------  ------\n",
      "  0       0        7414.59   1285.60    0.04    0.02    0.21    0.00\n",
      "  0       2       14553.37   2383.28    0.04    0.02    0.21    0.00\n",
      "  0       4       14393.63   2311.71    0.04    0.02    0.21    0.00\n",
      "[+] Saved pipeline to output directory\n",
      "output\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-08-20 00:41:09,934] [INFO] Set up nlp object from config\n",
      "[2022-08-20 00:41:09,941] [INFO] Pipeline: ['transformer', 'ner']\n",
      "[2022-08-20 00:41:09,944] [INFO] Created vocabulary\n",
      "[2022-08-20 00:41:09,944] [INFO] Finished initializing nlp object\n",
      "\n",
      "Downloading config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]\n",
      "Downloading config.json: 100%|##########| 481/481 [00:00<00:00, 480kB/s]\n",
      "\n",
      "Downloading vocab.json:   0%|          | 0.00/878k [00:00<?, ?B/s]\n",
      "Downloading vocab.json:   1%|1         | 12.0k/878k [00:00<00:16, 55.4kB/s]\n",
      "Downloading vocab.json:   5%|4         | 41.0k/878k [00:00<00:08, 102kB/s] \n",
      "Downloading vocab.json:  11%|#         | 96.0k/878k [00:00<00:04, 171kB/s]\n",
      "Downloading vocab.json:  20%|##        | 176k/878k [00:00<00:02, 249kB/s] \n",
      "Downloading vocab.json:  27%|##7       | 240k/878k [00:01<00:02, 265kB/s]\n",
      "Downloading vocab.json:  36%|###6      | 320k/878k [00:01<00:01, 299kB/s]\n",
      "Downloading vocab.json:  46%|####5     | 400k/878k [00:01<00:01, 321kB/s]\n",
      "Downloading vocab.json:  55%|#####4    | 480k/878k [00:01<00:01, 336kB/s]\n",
      "Downloading vocab.json:  64%|######3   | 560k/878k [00:02<00:00, 346kB/s]\n",
      "Downloading vocab.json:  75%|#######4  | 656k/878k [00:02<00:00, 376kB/s]\n",
      "Downloading vocab.json:  86%|########5 | 752k/878k [00:02<00:00, 396kB/s]\n",
      "Downloading vocab.json:  95%|#########4| 832k/878k [00:02<00:00, 387kB/s]\n",
      "Downloading vocab.json: 100%|##########| 878k/878k [00:02<00:00, 336kB/s]\n",
      "\n",
      "Downloading merges.txt:   0%|          | 0.00/446k [00:00<?, ?B/s]\n",
      "Downloading merges.txt:   3%|2         | 12.0k/446k [00:00<00:08, 54.6kB/s]\n",
      "Downloading merges.txt:   9%|8         | 40.0k/446k [00:00<00:04, 97.2kB/s]\n",
      "Downloading merges.txt:  20%|#9        | 88.0k/446k [00:00<00:02, 152kB/s] \n",
      "Downloading merges.txt:  36%|###5      | 160k/446k [00:00<00:01, 221kB/s] \n",
      "Downloading merges.txt:  50%|#####     | 224k/446k [00:01<00:00, 246kB/s]\n",
      "Downloading merges.txt:  68%|######8   | 304k/446k [00:01<00:00, 284kB/s]\n",
      "Downloading merges.txt:  86%|########6 | 384k/446k [00:01<00:00, 310kB/s]\n",
      "Downloading merges.txt: 100%|##########| 446k/446k [00:01<00:00, 287kB/s]\n",
      "\n",
      "Downloading tokenizer.json:   0%|          | 0.00/1.29M [00:00<?, ?B/s]\n",
      "Downloading tokenizer.json:   1%|          | 12.0k/1.29M [00:00<00:24, 55.4kB/s]\n",
      "Downloading tokenizer.json:   3%|3         | 41.0k/1.29M [00:00<00:12, 101kB/s] \n",
      "Downloading tokenizer.json:   7%|6         | 90.0k/1.29M [00:00<00:07, 158kB/s]\n",
      "Downloading tokenizer.json:  10%|9         | 131k/1.29M [00:00<00:07, 170kB/s] \n",
      "Downloading tokenizer.json:  14%|#3        | 179k/1.29M [00:01<00:06, 189kB/s]\n",
      "Downloading tokenizer.json:  18%|#8        | 243k/1.29M [00:01<00:04, 225kB/s]\n",
      "Downloading tokenizer.json:  22%|##1       | 291k/1.29M [00:01<00:04, 224kB/s]\n",
      "Downloading tokenizer.json:  27%|##6       | 355k/1.29M [00:01<00:04, 245kB/s]\n",
      "Downloading tokenizer.json:  32%|###1      | 419k/1.29M [00:02<00:03, 261kB/s]\n",
      "Downloading tokenizer.json:  36%|###6      | 483k/1.29M [00:02<00:03, 271kB/s]\n",
      "Downloading tokenizer.json:  41%|####1     | 547k/1.29M [00:02<00:02, 279kB/s]\n",
      "Downloading tokenizer.json:  46%|####6     | 611k/1.29M [00:02<00:02, 284kB/s]\n",
      "Downloading tokenizer.json:  51%|#####     | 675k/1.29M [00:02<00:02, 287kB/s]\n",
      "Downloading tokenizer.json:  56%|#####5    | 739k/1.29M [00:03<00:02, 289kB/s]\n",
      "Downloading tokenizer.json:  62%|######1   | 819k/1.29M [00:03<00:01, 312kB/s]\n",
      "Downloading tokenizer.json:  67%|######6   | 883k/1.29M [00:03<00:01, 307kB/s]\n",
      "Downloading tokenizer.json:  72%|#######1  | 947k/1.29M [00:03<00:01, 303kB/s]\n",
      "Downloading tokenizer.json:  76%|#######6  | 0.99M/1.29M [00:04<00:01, 301kB/s]\n",
      "Downloading tokenizer.json:  81%|########1 | 1.05M/1.29M [00:04<00:00, 298kB/s]\n",
      "Downloading tokenizer.json:  87%|########7 | 1.13M/1.29M [00:04<00:00, 319kB/s]\n",
      "Downloading tokenizer.json:  92%|#########2| 1.19M/1.29M [00:04<00:00, 311kB/s]\n",
      "Downloading tokenizer.json:  97%|#########6| 1.25M/1.29M [00:04<00:00, 306kB/s]\n",
      "Downloading tokenizer.json: 100%|##########| 1.29M/1.29M [00:04<00:00, 277kB/s]\n",
      "\n",
      "Downloading pytorch_model.bin:   0%|          | 0.00/478M [00:00<?, ?B/s]\n",
      "Downloading pytorch_model.bin:   1%|          | 2.54M/478M [00:00<00:18, 26.6MB/s]\n",
      "Downloading pytorch_model.bin:   1%|1         | 6.22M/478M [00:00<00:14, 33.5MB/s]\n",
      "Downloading pytorch_model.bin:   2%|2         | 10.0M/478M [00:00<00:13, 36.2MB/s]\n",
      "Downloading pytorch_model.bin:   3%|2         | 13.8M/478M [00:00<00:12, 37.4MB/s]\n",
      "Downloading pytorch_model.bin:   4%|3         | 17.3M/478M [00:00<00:12, 37.4MB/s]\n",
      "Downloading pytorch_model.bin:   4%|4         | 20.9M/478M [00:00<00:12, 37.3MB/s]\n",
      "Downloading pytorch_model.bin:   5%|5         | 24.5M/478M [00:00<00:12, 37.4MB/s]\n",
      "Downloading pytorch_model.bin:   6%|5         | 28.1M/478M [00:00<00:12, 37.3MB/s]\n",
      "Downloading pytorch_model.bin:   7%|6         | 31.6M/478M [00:00<00:12, 37.3MB/s]\n",
      "Downloading pytorch_model.bin:   7%|7         | 35.2M/478M [00:01<00:13, 35.4MB/s]\n",
      "Downloading pytorch_model.bin:   8%|8         | 39.0M/478M [00:01<00:12, 36.7MB/s]\n",
      "Downloading pytorch_model.bin:   9%|8         | 42.5M/478M [00:01<00:12, 36.5MB/s]\n",
      "Downloading pytorch_model.bin:  10%|9         | 46.4M/478M [00:01<00:12, 37.6MB/s]\n",
      "Downloading pytorch_model.bin:  10%|#         | 50.0M/478M [00:01<00:13, 33.2MB/s]\n",
      "Downloading pytorch_model.bin:  11%|#1        | 53.9M/478M [00:01<00:12, 35.2MB/s]\n",
      "Downloading pytorch_model.bin:  12%|#2        | 57.8M/478M [00:01<00:11, 36.8MB/s]\n",
      "Downloading pytorch_model.bin:  13%|#2        | 61.4M/478M [00:01<00:11, 37.0MB/s]\n",
      "Downloading pytorch_model.bin:  14%|#3        | 65.0M/478M [00:01<00:12, 35.7MB/s]\n",
      "Downloading pytorch_model.bin:  14%|#4        | 68.4M/478M [00:02<00:13, 32.4MB/s]\n",
      "Downloading pytorch_model.bin:  15%|#5        | 71.7M/478M [00:02<00:12, 33.0MB/s]\n",
      "Downloading pytorch_model.bin:  16%|#5        | 75.0M/478M [00:02<00:12, 33.3MB/s]\n",
      "Downloading pytorch_model.bin:  16%|#6        | 78.5M/478M [00:02<00:12, 34.1MB/s]\n",
      "Downloading pytorch_model.bin:  17%|#7        | 81.7M/478M [00:02<00:12, 34.1MB/s]\n",
      "Downloading pytorch_model.bin:  18%|#7        | 85.0M/478M [00:02<00:12, 33.8MB/s]\n",
      "Downloading pytorch_model.bin:  18%|#8        | 88.3M/478M [00:02<00:11, 34.1MB/s]\n",
      "Downloading pytorch_model.bin:  19%|#9        | 92.5M/478M [00:02<00:10, 37.0MB/s]\n",
      "Downloading pytorch_model.bin:  20%|##        | 96.7M/478M [00:02<00:10, 38.9MB/s]\n",
      "Downloading pytorch_model.bin:  21%|##1       | 100M/478M [00:02<00:10, 38.8MB/s] \n",
      "Downloading pytorch_model.bin:  22%|##1       | 104M/478M [00:03<00:10, 38.0MB/s]\n",
      "Downloading pytorch_model.bin:  23%|##2       | 108M/478M [00:03<00:35, 10.8MB/s]\n",
      "Downloading pytorch_model.bin:  23%|##3       | 112M/478M [00:04<00:27, 14.2MB/s]\n",
      "Downloading pytorch_model.bin:  24%|##4       | 115M/478M [00:04<00:22, 17.2MB/s]\n",
      "Downloading pytorch_model.bin:  25%|##4       | 119M/478M [00:04<00:18, 20.4MB/s]\n",
      "Downloading pytorch_model.bin:  26%|##5       | 123M/478M [00:04<00:15, 23.6MB/s]\n",
      "Downloading pytorch_model.bin:  26%|##6       | 126M/478M [00:04<00:13, 26.5MB/s]\n",
      "Downloading pytorch_model.bin:  27%|##7       | 130M/478M [00:04<00:12, 28.9MB/s]\n",
      "Downloading pytorch_model.bin:  28%|##7       | 133M/478M [00:04<00:11, 31.0MB/s]\n",
      "Downloading pytorch_model.bin:  29%|##8       | 137M/478M [00:04<00:10, 32.7MB/s]\n",
      "Downloading pytorch_model.bin:  29%|##9       | 140M/478M [00:04<00:10, 34.0MB/s]\n",
      "Downloading pytorch_model.bin:  30%|###       | 144M/478M [00:05<00:10, 34.8MB/s]\n",
      "Downloading pytorch_model.bin:  31%|###       | 148M/478M [00:05<00:09, 35.6MB/s]\n",
      "Downloading pytorch_model.bin:  32%|###1      | 151M/478M [00:05<00:09, 34.8MB/s]\n",
      "Downloading pytorch_model.bin:  32%|###2      | 155M/478M [00:05<00:10, 33.6MB/s]\n",
      "Downloading pytorch_model.bin:  33%|###3      | 158M/478M [00:05<00:10, 32.3MB/s]\n",
      "Downloading pytorch_model.bin:  34%|###3      | 161M/478M [00:05<00:10, 32.6MB/s]\n",
      "Downloading pytorch_model.bin:  34%|###4      | 165M/478M [00:05<00:09, 34.2MB/s]\n",
      "Downloading pytorch_model.bin:  35%|###5      | 168M/478M [00:05<00:09, 35.0MB/s]\n",
      "Downloading pytorch_model.bin:  36%|###5      | 172M/478M [00:05<00:08, 35.7MB/s]\n",
      "Downloading pytorch_model.bin:  37%|###6      | 175M/478M [00:05<00:08, 36.2MB/s]\n",
      "Downloading pytorch_model.bin:  37%|###7      | 179M/478M [00:06<00:08, 36.6MB/s]\n",
      "Downloading pytorch_model.bin:  38%|###8      | 183M/478M [00:06<00:08, 36.8MB/s]\n",
      "Downloading pytorch_model.bin:  39%|###8      | 186M/478M [00:06<00:08, 36.9MB/s]\n",
      "Downloading pytorch_model.bin:  40%|###9      | 190M/478M [00:06<00:08, 37.0MB/s]\n",
      "Downloading pytorch_model.bin:  40%|####      | 193M/478M [00:06<00:08, 37.1MB/s]\n",
      "Downloading pytorch_model.bin:  41%|####1     | 197M/478M [00:06<00:07, 37.2MB/s]\n",
      "Downloading pytorch_model.bin:  42%|####1     | 200M/478M [00:06<00:07, 37.0MB/s]\n",
      "Downloading pytorch_model.bin:  43%|####2     | 204M/478M [00:06<00:07, 37.3MB/s]\n",
      "Downloading pytorch_model.bin:  43%|####3     | 208M/478M [00:06<00:07, 37.2MB/s]\n",
      "Downloading pytorch_model.bin:  44%|####4     | 211M/478M [00:06<00:07, 37.3MB/s]\n",
      "Downloading pytorch_model.bin:  45%|####4     | 215M/478M [00:07<00:07, 37.3MB/s]\n",
      "Downloading pytorch_model.bin:  46%|####5     | 218M/478M [00:07<00:07, 37.3MB/s]\n",
      "Downloading pytorch_model.bin:  46%|####6     | 222M/478M [00:07<00:07, 37.3MB/s]\n",
      "Downloading pytorch_model.bin:  47%|####7     | 226M/478M [00:07<00:07, 37.1MB/s]\n",
      "Downloading pytorch_model.bin:  48%|####7     | 229M/478M [00:07<00:06, 37.3MB/s]\n",
      "Downloading pytorch_model.bin:  49%|####8     | 233M/478M [00:07<00:06, 37.4MB/s]\n",
      "Downloading pytorch_model.bin:  49%|####9     | 236M/478M [00:07<00:06, 37.4MB/s]\n",
      "Downloading pytorch_model.bin:  50%|#####     | 240M/478M [00:07<00:06, 37.3MB/s]\n",
      "Downloading pytorch_model.bin:  51%|#####     | 244M/478M [00:07<00:06, 37.4MB/s]\n",
      "Downloading pytorch_model.bin:  52%|#####1    | 247M/478M [00:07<00:06, 37.4MB/s]\n",
      "Downloading pytorch_model.bin:  52%|#####2    | 251M/478M [00:08<00:06, 37.4MB/s]\n",
      "Downloading pytorch_model.bin:  53%|#####3    | 254M/478M [00:08<00:06, 37.0MB/s]\n",
      "Downloading pytorch_model.bin:  54%|#####3    | 258M/478M [00:08<00:06, 37.2MB/s]\n",
      "Downloading pytorch_model.bin:  55%|#####4    | 262M/478M [00:08<00:06, 37.4MB/s]\n",
      "Downloading pytorch_model.bin:  55%|#####5    | 265M/478M [00:08<00:05, 37.4MB/s]\n",
      "Downloading pytorch_model.bin:  56%|#####6    | 269M/478M [00:08<00:05, 37.3MB/s]\n",
      "Downloading pytorch_model.bin:  57%|#####6    | 272M/478M [00:08<00:05, 37.4MB/s]\n",
      "Downloading pytorch_model.bin:  58%|#####7    | 276M/478M [00:08<00:05, 37.2MB/s]\n",
      "Downloading pytorch_model.bin:  58%|#####8    | 279M/478M [00:08<00:05, 37.4MB/s]\n",
      "Downloading pytorch_model.bin:  59%|#####9    | 283M/478M [00:08<00:05, 36.7MB/s]\n",
      "Downloading pytorch_model.bin:  60%|######    | 287M/478M [00:09<00:05, 37.5MB/s]\n",
      "Downloading pytorch_model.bin:  61%|######    | 290M/478M [00:09<00:05, 37.5MB/s]\n",
      "Downloading pytorch_model.bin:  62%|######1   | 294M/478M [00:09<00:05, 37.5MB/s]\n",
      "Downloading pytorch_model.bin:  62%|######2   | 298M/478M [00:09<00:05, 37.4MB/s]\n",
      "Downloading pytorch_model.bin:  63%|######3   | 301M/478M [00:09<00:04, 37.4MB/s]\n",
      "Downloading pytorch_model.bin:  64%|######3   | 305M/478M [00:09<00:04, 37.4MB/s]\n",
      "Downloading pytorch_model.bin:  64%|######4   | 308M/478M [00:09<00:04, 37.3MB/s]\n",
      "Downloading pytorch_model.bin:  65%|######5   | 312M/478M [00:09<00:04, 37.3MB/s]\n",
      "Downloading pytorch_model.bin:  66%|######5   | 315M/478M [00:09<00:04, 37.3MB/s]\n",
      "Downloading pytorch_model.bin:  67%|######6   | 319M/478M [00:09<00:04, 37.3MB/s]\n",
      "Downloading pytorch_model.bin:  67%|######7   | 323M/478M [00:10<00:04, 37.3MB/s]\n",
      "Downloading pytorch_model.bin:  68%|######8   | 326M/478M [00:10<00:04, 37.3MB/s]\n",
      "Downloading pytorch_model.bin:  69%|######8   | 330M/478M [00:10<00:04, 37.3MB/s]\n",
      "Downloading pytorch_model.bin:  70%|######9   | 333M/478M [00:10<00:04, 37.3MB/s]\n",
      "Downloading pytorch_model.bin:  70%|#######   | 337M/478M [00:10<00:04, 36.4MB/s]\n",
      "Downloading pytorch_model.bin:  71%|#######1  | 341M/478M [00:10<00:03, 37.0MB/s]\n",
      "Downloading pytorch_model.bin:  72%|#######2  | 344M/478M [00:10<00:03, 37.7MB/s]\n",
      "Downloading pytorch_model.bin:  73%|#######2  | 348M/478M [00:10<00:03, 37.7MB/s]\n",
      "Downloading pytorch_model.bin:  74%|#######3  | 352M/478M [00:10<00:03, 37.3MB/s]\n",
      "Downloading pytorch_model.bin:  74%|#######4  | 355M/478M [00:10<00:03, 37.5MB/s]\n",
      "Downloading pytorch_model.bin:  75%|#######5  | 359M/478M [00:11<00:03, 37.4MB/s]\n",
      "Downloading pytorch_model.bin:  76%|#######5  | 362M/478M [00:11<00:03, 37.3MB/s]\n",
      "Downloading pytorch_model.bin:  77%|#######6  | 366M/478M [00:11<00:03, 37.3MB/s]\n",
      "Downloading pytorch_model.bin:  77%|#######7  | 369M/478M [00:11<00:03, 37.4MB/s]\n",
      "Downloading pytorch_model.bin:  78%|#######8  | 373M/478M [00:12<00:12, 8.53MB/s]\n",
      "Downloading pytorch_model.bin:  79%|#######8  | 377M/478M [00:12<00:09, 11.7MB/s]\n",
      "Downloading pytorch_model.bin:  80%|#######9  | 381M/478M [00:12<00:06, 15.2MB/s]\n",
      "Downloading pytorch_model.bin:  81%|########  | 385M/478M [00:12<00:05, 18.2MB/s]\n",
      "Downloading pytorch_model.bin:  81%|########1 | 388M/478M [00:13<00:04, 21.2MB/s]\n",
      "Downloading pytorch_model.bin:  82%|########2 | 392M/478M [00:13<00:03, 24.5MB/s]\n",
      "Downloading pytorch_model.bin:  83%|########2 | 396M/478M [00:13<00:03, 27.3MB/s]\n",
      "Downloading pytorch_model.bin:  84%|########3 | 399M/478M [00:13<00:02, 29.6MB/s]\n",
      "Downloading pytorch_model.bin:  84%|########4 | 403M/478M [00:13<00:02, 31.6MB/s]\n",
      "Downloading pytorch_model.bin:  85%|########5 | 406M/478M [00:13<00:02, 33.0MB/s]\n",
      "Downloading pytorch_model.bin:  86%|########5 | 410M/478M [00:13<00:02, 34.3MB/s]\n",
      "Downloading pytorch_model.bin:  87%|########6 | 414M/478M [00:13<00:01, 35.2MB/s]\n",
      "Downloading pytorch_model.bin:  87%|########7 | 417M/478M [00:13<00:01, 35.8MB/s]\n",
      "Downloading pytorch_model.bin:  88%|########8 | 421M/478M [00:13<00:01, 36.2MB/s]\n",
      "Downloading pytorch_model.bin:  89%|########8 | 424M/478M [00:14<00:01, 36.6MB/s]\n",
      "Downloading pytorch_model.bin:  90%|########9 | 428M/478M [00:14<00:01, 36.8MB/s]\n",
      "Downloading pytorch_model.bin:  90%|######### | 431M/478M [00:14<00:01, 36.9MB/s]\n",
      "Downloading pytorch_model.bin:  91%|######### | 435M/478M [00:14<00:01, 37.0MB/s]\n",
      "Downloading pytorch_model.bin:  92%|#########1| 439M/478M [00:14<00:01, 37.1MB/s]\n",
      "Downloading pytorch_model.bin:  92%|#########2| 442M/478M [00:14<00:01, 37.2MB/s]\n",
      "Downloading pytorch_model.bin:  93%|#########3| 446M/478M [00:14<00:00, 37.2MB/s]\n",
      "Downloading pytorch_model.bin:  94%|#########3| 449M/478M [00:14<00:00, 37.2MB/s]\n",
      "Downloading pytorch_model.bin:  95%|#########4| 453M/478M [00:14<00:00, 37.3MB/s]\n",
      "Downloading pytorch_model.bin:  95%|#########5| 456M/478M [00:14<00:00, 37.3MB/s]\n",
      "Downloading pytorch_model.bin:  96%|#########6| 460M/478M [00:15<00:00, 37.3MB/s]\n",
      "Downloading pytorch_model.bin:  97%|#########6| 464M/478M [00:15<00:00, 37.3MB/s]\n",
      "Downloading pytorch_model.bin:  98%|#########7| 467M/478M [00:15<00:00, 37.3MB/s]\n",
      "Downloading pytorch_model.bin:  98%|#########8| 471M/478M [00:15<00:00, 37.3MB/s]\n",
      "Downloading pytorch_model.bin:  99%|#########9| 474M/478M [00:15<00:00, 37.3MB/s]\n",
      "Downloading pytorch_model.bin: 100%|#########9| 478M/478M [00:15<00:00, 37.3MB/s]\n",
      "Downloading pytorch_model.bin: 100%|##########| 478M/478M [00:15<00:00, 32.2MB/s]\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "C:\\Users\\DeepLearning\\envs\\official_Tasks\\lib\\site-packages\\torch\\amp\\autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "[2022-08-20 00:41:52,796] [INFO] Initialized pipeline components: ['transformer', 'ner']\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train output1.cfg --output ./output --paths.train ./train_data.spacy --paths.dev ./test_data.spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61d9e4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Created output directory: output"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DeepLearning\\envs\\official_Tasks\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "[2022-08-20 01:18:19,427] [INFO] Set up nlp object from config\n",
      "[2022-08-20 01:18:19,440] [INFO] Pipeline: ['transformer', 'ner']\n",
      "[2022-08-20 01:18:19,444] [INFO] Created vocabulary\n",
      "[2022-08-20 01:18:19,445] [INFO] Finished initializing nlp object\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "C:\\Users\\DeepLearning\\envs\\official_Tasks\\lib\\site-packages\\torch\\amp\\autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "[2022-08-20 01:18:34,364] [INFO] Initialized pipeline components: ['transformer', 'ner']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[i] Saving to output directory: output\n",
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['transformer', 'ner']\n",
      "[i] Initial learn rate: 0.0\n",
      "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  -------------  --------  ------  ------  ------  ------\n",
      "  0       0        7414.59   1285.60    0.04    0.02    0.21    0.00\n",
      "  0       2       14553.37   2383.28    0.04    0.02    0.21    0.00\n",
      "  0       4       14393.63   2311.71    0.04    0.02    0.21    0.00\n",
      "[+] Saved pipeline to output directory\n",
      "output\\model-last\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train output1.cfg --output ./output --paths.train ./train_data.spacy --paths.dev ./test_data.spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8c5ea4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2021 NVIDIA Corporation\n",
      "Built on Fri_Dec_17_18:28:54_Pacific_Standard_Time_2021\n",
      "Cuda compilation tools, release 11.6, V11.6.55\n",
      "Build cuda_11.6.r11.6/compiler.30794723_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d673df55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76059c88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "691c4e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Created output directory: output\n",
      "[i] Saving to output directory: output\n",
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['transformer', 'ner']\n",
      "[i] Initial learn rate: 0.0\n",
      "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  -------------  --------  ------  ------  ------  ------\n",
      "  0       0        7414.47   1285.60    0.00    0.00    0.00    0.00\n",
      "[!] Aborting and saving the final best model. Encountered exception:\n",
      "ValueError(\"[E024] Could not find an optimal move to supervise the parser.\n",
      "Usually, this means that the model can't be updated in a way that's valid and\n",
      "satisfies the correct annotations specified in the GoldParse. For example, are\n",
      "all labels added to the model? If you're training a named entity recognizer,\n",
      "also make sure that none of your annotated entity spans have leading or trailing\n",
      "whitespace or punctuation. You can also use the `debug data` command to validate\n",
      "your JSON-formatted training data. For details, run:\\npython -m spacy debug data\n",
      "--help\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DeepLearning\\envs\\official_Tasks\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "[2022-08-20 09:07:11,654] [INFO] Set up nlp object from config\n",
      "[2022-08-20 09:07:11,662] [INFO] Pipeline: ['transformer', 'ner']\n",
      "[2022-08-20 09:07:11,665] [INFO] Created vocabulary\n",
      "[2022-08-20 09:07:11,665] [INFO] Finished initializing nlp object\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "C:\\Users\\DeepLearning\\envs\\official_Tasks\\lib\\site-packages\\torch\\amp\\autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "[2022-08-20 09:07:26,778] [INFO] Initialized pipeline components: ['transformer', 'ner']\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\DeepLearning\\envs\\official_Tasks\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\DeepLearning\\envs\\official_Tasks\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\DeepLearning\\envs\\official_Tasks\\lib\\site-packages\\spacy\\__main__.py\", line 4, in <module>\n",
      "    setup_cli()\n",
      "  File \"C:\\Users\\DeepLearning\\envs\\official_Tasks\\lib\\site-packages\\spacy\\cli\\_util.py\", line 71, in setup_cli\n",
      "    command(prog_name=COMMAND)\n",
      "  File \"C:\\Users\\DeepLearning\\envs\\official_Tasks\\lib\\site-packages\\click\\core.py\", line 1128, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "  File \"C:\\Users\\DeepLearning\\envs\\official_Tasks\\lib\\site-packages\\click\\core.py\", line 1053, in main\n",
      "    rv = self.invoke(ctx)\n",
      "  File \"C:\\Users\\DeepLearning\\envs\\official_Tasks\\lib\\site-packages\\click\\core.py\", line 1659, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "  File \"C:\\Users\\DeepLearning\\envs\\official_Tasks\\lib\\site-packages\\click\\core.py\", line 1395, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "  File \"C:\\Users\\DeepLearning\\envs\\official_Tasks\\lib\\site-packages\\click\\core.py\", line 754, in invoke\n",
      "    return __callback(*args, **kwargs)\n",
      "  File \"C:\\Users\\DeepLearning\\envs\\official_Tasks\\lib\\site-packages\\typer\\main.py\", line 532, in wrapper\n",
      "    return callback(**use_params)  # type: ignore\n",
      "  File \"C:\\Users\\DeepLearning\\envs\\official_Tasks\\lib\\site-packages\\spacy\\cli\\train.py\", line 45, in train_cli\n",
      "    train(config_path, output_path, use_gpu=use_gpu, overrides=overrides)\n",
      "  File \"C:\\Users\\DeepLearning\\envs\\official_Tasks\\lib\\site-packages\\spacy\\cli\\train.py\", line 75, in train\n",
      "    train_nlp(nlp, output_path, use_gpu=use_gpu, stdout=sys.stdout, stderr=sys.stderr)\n",
      "  File \"C:\\Users\\DeepLearning\\envs\\official_Tasks\\lib\\site-packages\\spacy\\training\\loop.py\", line 122, in train\n",
      "    raise e\n",
      "  File \"C:\\Users\\DeepLearning\\envs\\official_Tasks\\lib\\site-packages\\spacy\\training\\loop.py\", line 105, in train\n",
      "    for batch, info, is_best_checkpoint in training_step_iterator:\n",
      "  File \"C:\\Users\\DeepLearning\\envs\\official_Tasks\\lib\\site-packages\\spacy\\training\\loop.py\", line 203, in train_while_improving\n",
      "    nlp.update(\n",
      "  File \"C:\\Users\\DeepLearning\\envs\\official_Tasks\\lib\\site-packages\\spacy\\language.py\", line 1164, in update\n",
      "    proc.update(examples, sgd=None, losses=losses, **component_cfg[name])  # type: ignore\n",
      "  File \"spacy\\pipeline\\transition_parser.pyx\", line 397, in spacy.pipeline.transition_parser.Parser.update\n",
      "  File \"spacy\\pipeline\\transition_parser.pyx\", line 653, in spacy.pipeline.transition_parser.Parser._init_gold_batch\n",
      "  File \"spacy\\pipeline\\_parser_internals\\transition_system.pyx\", line 132, in spacy.pipeline._parser_internals.transition_system.TransitionSystem.get_oracle_sequence_from_state\n",
      "ValueError: [E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the `debug data` command to validate your JSON-formatted training data. For details, run:\n",
      "python -m spacy debug data --help\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train output1.cfg --output ./output --paths.train ./train_data.spacy --paths.dev ./test_data.spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d99b50c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: python -m spacy debug data [OPTIONS] CONFIG_PATH\n",
      "\n",
      "  Analyze, debug and validate your training and development data. Outputs\n",
      "  useful stats, and can help you find problems like invalid entity\n",
      "  annotations, cyclic dependencies, low data labels and more.\n",
      "\n",
      "  DOCS: https://spacy.io/api/cli#debug-data\n",
      "\n",
      "Arguments:\n",
      "  CONFIG_PATH  Path to config file  [required]\n",
      "\n",
      "Options:\n",
      "  -c, --code-path, --code PATH  Path to Python file with additional code\n",
      "                                (registered functions) to be imported\n",
      "  -IW, --ignore-warnings        Ignore warnings, only show stats and errors\n",
      "  -V, --verbose                 Print additional information and explanations\n",
      "  -NF, --no-format              Don't pretty-print the results\n",
      "  --help                        Show this message and exit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DeepLearning\\envs\\official_Tasks\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy debug data --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e3ae360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(action= 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98a35765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[x] Path to Python code not found\n",
      "--ignore-warnings\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DeepLearning\\envs\\official_Tasks\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy debug data output1.cfg --code --ignore-warnings --verbose --no-format --paths.train ./train_data.spacy --paths.dev ./test_data.spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62b2643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8833a950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b995802",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
